---
title: '[Paper Review] Mobile, Egocentric Human Body Motion Reconstruction Using Only Eyeglasses-mounted Cameras and a Few Body-worn Inertial Sensors Paper Review'
date: 2023-01-10 00:00:01
categories:
- Paper Review
tags: PoseEstimation Egocentric Reconstruction IMU
comments: true
use_math: true
---


[Paper Review] [Mobile. Egocentric Human Body Motion Reconstruction Using Only Eyeglasses-mounted Cameras and a Few Body-worn Inertial Sensors](https://par.nsf.gov/servlets/purl/10300348)

<!-- more -->

# Abstract

- ì‚¬ìš©ìë“¤ì´ ì‹œê³µê°„ êµ¬ì•  ì—†ì´ ì´ìš©í•  ìˆ˜ ìˆëŠ” í¸ë¦¬í•œ **telepresence(ì›ê²© í˜„ì¥) ì‹œìŠ¤í…œ**ì„ êµ¬ìƒ
- ë¨¸ë¦¬ì— ì°©ìš©í•˜ëŠ” ì¥ì¹˜ì— ë‚´ì¥ëœ **ì¹´ë©”ë¼**ì™€ ì†ëª©ê³¼ ë°œëª©ì— ì°©ìš©í•˜ëŠ” **IMU(ê´€ì„± ì¸¡ì • ì¥ì¹˜)**ë¥¼ í†µí•´ ì‚¬ëŒì˜ **ë™ì  3D ìº¡ì²˜**ë¥¼ ìœ„í•œ **ë…ë¦½í˜• ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ** ì œì‹œ
- ë³¸ ë…¼ë¬¸ì˜ í”„ë¡œí† íƒ€ì… ì‹œìŠ¤í…œì€ **í•™ìŠµ ê¸°ë°˜ í¬ì¦ˆ ì¶”ì •**ì„ í†µí•´ ì°©ìš©ìì˜ ë™ì‘ì„ ìê¸° ì¤‘ì‹¬ì ìœ¼ë¡œ ì¬êµ¬ì„±
- **ì‹œê°(visual) ë° ê´€ì„±(inertial) ì„¼ì„œ**ì˜ ì…ë ¥ì„ ìœµí•© â†’ 1) head-worn viewsì˜ ì¼ê´€ì„± ì—†ëŠ” íŒ”ë‹¤ë¦¬ì˜ ê°€ì‹œì„± 2) í¬ì†Œ IMUì˜ ëª¨í˜¸ì„±ê³¼ ê°™ì€ **ë¬¸ì œ**ë¥¼ ê·¹ë³µ
- ì¶”ì •ëœ í¬ì¦ˆëŠ” prescanned surface modelë¡œ ì§€ì†ì ìœ¼ë¡œ **ë¦¬íƒ€ê²ŸíŒ…**ë˜ì–´ high-fidelity(ì¶©ì‹¤ë„)ê°€ ë†’ì€ **3D reconstruction**ì„ ì´ˆë˜
- ë‹¤ì–‘í•œ ì¸ì²´ ì›€ì§ì„ì„ ì¬êµ¬ì„±í•˜ì—¬ ì‹œìŠ¤í…œì„ ì‹œì—°í•˜ê³  ì‹¤ì‹œê°„ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” **visual-inertial í•™ìŠµ ê¸°ë°˜ ë°©ë²•**ì´ ì‹œê° ì „ìš© ë° ê´€ì„± ì „ìš© ì ‘ê·¼ ë°©ì‹ **ëŠ¥ê°€**
- [https://sites.google.com/site/youngwooncha/egovip](https://sites.google.com/site/youngwooncha/egovip)

---

# Introduction

- telepresenceëŠ” ë–¨ì–´ì ¸ ìˆëŠ” ê³µê°„ì—ì„œë„ ì›ê²© ì‚¬íšŒì  ìƒí˜¸ ì‘ìš©ì„ ê°€ëŠ¥í•˜ê²Œ í•¨
- ì§€ê¸ˆê¹Œì§€ì˜ ë¬¸ì œ
    - eyeglass-frame formì˜ ë¬¸ì œ :  íŒ”ë‹¤ë¦¬ì˜ ê°€ì‹œì„± ë–¨ì–´ì§ 
    - í”„ë ˆì„ë³„ ì‹œê°ì  3D í¬ì¦ˆ ì¶”ì • ë°©ë²• : ê°€ë ¤ì§„ ê´€ì ˆì—ì„œëŠ” ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ì¶”ì •ì¹˜
    - ì™¸ë¶€ ì¹´ë©”ë¼ ìº¡ì²˜ ë°©ë²• : ì‹¤ì‹œê°„ìœ¼ë¡œ ë†’ì€ ì •í™•ë„ì™€ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ì§€ë§Œ, ëª¨ë“  ê´€ì ˆì´ ë³´ì—¬ì•¼ í•¨
    - Joint heatmap ì¶”ì • ë°©ë²• : 2D heatmap ë‚´ì—ì„œ ë ˆì´ë¸”ì„ ì§€ì •í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— ì˜ìƒ ì™¸ë¶€ì— ìˆëŠ” jointë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŒ â†’ ê²½ê³„ë¥¼ íŒ¨ë”©í•˜ì—¬ íˆíŠ¸ë§µ í¬ê¸°ë¥¼ í™•ì¥í•˜ë©´ ì™€ì´ë“œ FoV ë˜ëŠ” ì–´ì•ˆ ë Œì¦ˆì˜ ì™œê³¡ì´ í¬ê¸° ë•Œë¬¸ì— ë†’ì€ 3D ì¡°ì¸íŠ¸ ì˜¤ë¥˜ê°€ ë°œìƒí•  ê°€ëŠ¥ì„±

- ì‹œê°-ê´€ì„± ìœµí•© ì ‘ê·¼ë²•ì€ 10ê°œ ì´ìƒì˜ ì‹ ì²´ ì°©ìš© ì„¼ì„œê°€ í•„ìš”
- **eyeglass-frame mounted ì¹´ë©”ë¼ & ì†ëª©ê³¼ ë°œëª©ì˜ IMUì— ì˜ì¡´í•˜ëŠ” wearable 3D acquisition system ì œì•ˆ**
    1. visibility-aware visual 3D pose network : ê°€ë ¤ì§„ ê´€ì ˆì„ ì–µì œí•˜ë©´ì„œ ë³´ì´ëŠ” ê´€ì ˆ ì¶”ì •
    2. online IMU offset calibration method : ë¶€ì°©ëœ IMUê°€ ìˆëŠ” íŒ”ëšê³¼ ë‹¤ë¦¬ ì•„ë˜ì— ëŒ€í•´ ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ì‹œê°ì  ë° ê´€ì„± ë¼ˆ ë°©í–¥ì„ ì •ë ¬í•˜ì—¬ ê´€ì„± ì¸¡ì •ì„ í–¥ìƒ
    3. visual-inertial 3D pose network : IMUê°€ ì—†ëŠ” ìœ„ìª½ íŒ”ê³¼ í—ˆë²…ì§€ì˜ í¬ì¦ˆëŠ” ì´ì „ í”„ë ˆì„ì—ì„œì˜ ìœ„ìª½ ë¼ˆì˜ ì‹œê°ì  ê°ì§€ë¿ë§Œ ì•„ë‹ˆë¼ ìƒì‘í•˜ëŠ” ì•„ë˜ìª½ ë¼ˆì˜ ê´€ì„± ì¸¡ì •ì„ ì‚¬ìš©í•˜ì—¬ ì¶”ì •

### Contribution ###
- í¬ì†Œ ê°€ì‹œì„±ê³¼ í¬ì†Œ ê´€ì„± ì„¼ì„œë¥¼ ëª¨ë‘ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ìµœì´ˆì˜ ìê¸° ì¤‘ì‹¬ì  3D ì¸ê°„ ìì„¸ ì¶”ì • ì ‘ê·¼ë²•
- ëª¨ë°”ì¼ ìº¡ì²˜ ë° ì‹¤ì‹œê°„ ì‹ ì²´ ì›€ì§ì„ ì¶”ì •ì„ ìœ„í•œ ì•ˆê²½ í¼ íŒ©í„°ì˜ ì‘ë™ ì¤‘ì¸ ë…ë¦½ì ì¸ ê°œë… ì¦ëª… í”„ë¡œí† íƒ€ì…
- ê´€ì„± ì¸¡ì •ë¿ë§Œ ì•„ë‹ˆë¼ ê³µë™ ê°€ì‹œì„± ì •ë³´ê°€ ìˆëŠ” ì—¬ëŸ¬ ë·°ë¥¼ í¬í•¨í•˜ëŠ” ìµœì´ˆì˜ ìê¸° ì¤‘ì‹¬ì  ì¸ê°„ ëª¨ì…˜ ë°ì´í„° ì„¸íŠ¸

# RELATED WORK

## Body Reconstruction

- Deformable body model-based surface ì¶”ì •ì€ ì»´í“¨í„° ë¹„ì „ì— ì´ˆì  : [SMPL: A Skinned Multi-Person Linear Model](https://dl.acm.org/doi/pdf/10.1145/2816795.2818013)
- ëª¨ë¸ ë§¤ê°œë³€ìˆ˜ì˜ ì¶”ì •ì€ ì‹œê°ì  ìì„¸ ì¶”ì •ê³¼ í•¨ê»˜ ì¸ê°„ í‘œë©´ì„ ê·¼ì‚¬í™” : [2d human pose estimation: New benchmark and state of the art analysis](https://openaccess.thecvf.com/content_cvpr_2014/papers/Andriluka_2D_Human_Pose_2014_CVPR_paper.pdf)
    - ì‹ ì²´ ëª¨ë¸ê³¼ ì´ë¯¸ì§€ ì‚¬ì´ì˜ ë°€ë„ ë†’ì€ ëŒ€ì‘ ì¶”ì •([DensePose: Dense Human Pose Estimation In The Wild](https://openaccess.thecvf.com/content_cvpr_2018/papers/Guler_DensePose_Dense_Human_CVPR_2018_paper.pdf))
    - ì§ì ‘ì ì¸ volumetric ì¶”ë¡ ([Bodynet: Volumetric inference of 3d human body shapes](https://openaccess.thecvf.com/content_ECCV_2018/papers/Gul_Varol_BodyNet_Volumetric_Inference_ECCV_2018_paper.pdf))
- ìµœê·¼ ì—°êµ¬ëŠ” **real-time** ì„±ëŠ¥ì˜ í–¥ìƒ
    - ì–¼êµ´ ë° ì† í¬ì¦ˆ([Monocular total capture: Posing face, body, and hands in the wild](https://openaccess.thecvf.com/content_CVPR_2019/papers/Xiang_Monocular_Total_Capture_Posing_Face_Body_and_Hands_in_the_CVPR_2019_paper.pdf))
    - temporal pose([Vibe: Video inference for human body pose and shape estimation](https://openaccess.thecvf.com/content_CVPR_2020/papers/Kocabas_VIBE_Video_Inference_for_Human_Body_Pose_and_Shape_Estimation_CVPR_2020_paper.pdf))
- **High-fidelity geometry**ì˜ ì¶”ì •
    - fitting image silhouette([Livecap: Real-time human performance capture from monocular video](https://dl.acm.org/doi/pdf/10.1145/3311970?casa_token=tNDckmc-08YAAAAA:fasrAg-G1TPXYUCoI-4DuKQ3-oh1Dd5utgDBePVRrPiOjxtj0MDcamnHwVkP3IsKruCofJ4e5Vcs-sU))
    - cloth simulation([Simulcap: Single-view human performance capture with cloth simulation](https://openaccess.thecvf.com/content_CVPR_2019/papers/Yu_SimulCap__Single-View_Human_Performance_Capture_With_Cloth_Simulation_CVPR_2019_paper.pdf))
- í•´ë‹¹ ë°©ì‹ì€ ì™¸ë¶€ ì¹´ë©”ë¼ê°€ ì „ì‹ ì„ ë‹´ì„ ìˆ˜ ìˆì–´ì•¼ í•˜ì§€ë§Œ, egocentric viewì—ì„œ ì‹ ì²´ ë¶€ìœ„ê°€ ê°€ë ¤ì§ˆ ë•Œê°€ ìˆìŒ

## Visual Pose Estimation

- CNNì„ ì‚¬ìš©í•˜ì—¬ **2D joint heatmap** ê¸°ë°˜ ì¶”ì •
    - [Openpose: realtime multi-person 2d pose estimation using part affinity fields](https://openaccess.thecvf.com/content_cvpr_2017/papers/Cao_Realtime_Multi-Person_2D_CVPR_2017_paper.pdf)
    - [Stacked hourglass networks for human pose estimation](https://link.springer.com/chapter/10.1007/978-3-319-46484-8_29)
    - [Fast human pose estimation](https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Fast_Human_Pose_Estimation_CVPR_2019_paper.pdf)
- **CNN ê¸°ë°˜ 3D joint ì¶”ì •**ì€ ë‹¨ì¼ ì™¸ë¶€ ë·°ì— ëŒ€í•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ìƒë‹¹í•œ ì •í™•ë„ ë‹¬ì„±
    - [Xnect: Realtime multi-person 3d human pose estimation with a single rgb camera](https://pure.mpg.de/rest/items/item_3093760/component/file_3093762/content)
    - [Vnect: Real-time 3d human pose estimation with a single rgb camera](https://dl.acm.org/doi/pdf/10.1145/3072959.3073596?casa_token=jz76ZnIq5BwAAAAA:acSQFY2WBBH07kFdTBvDQ9PIsQZ6Lq4T7_jf2Z7Uk4xRCmgjmoNBgX83GGu73zd9YXXOteRgFNDYqck)
- Human pose constraintì™€ occlusion informationê°€ í›ˆë ¨ ì¤‘ì— í†µí•©
- **ì‹œê°„**ì´ ë”°ë¥¸ ì—°ì†ì ì¸ ì¸ê°„ ì›€ì§ì„ì˜ ê²½ìš°, **RNN ê¸°ë°˜ í¬ì¦ˆ ì¶”ì •**ì´ ì¼ë ¨ì˜ ì›€ì§ì„ ì˜ˆì¸¡ì— ëŒ€í•´ ìœ ë§í•œ ê²°ê³¼
    - [Deep representation learning for human motion prediction and classification](https://openaccess.thecvf.com/content_cvpr_2017/papers/Butepage_Deep_Representation_Learning_CVPR_2017_paper.pdf)
    - [On human motion prediction using recurrent neural networks](https://openaccess.thecvf.com/content_cvpr_2017/papers/Martinez_On_Human_Motion_CVPR_2017_paper.pdf)
    - [Learning to generate long-term future via hierarchical prediction](http://proceedings.mlr.press/v70/villegas17a/villegas17a.pdf)
- í•´ë‹¹ ë°©ì‹ì€ ê´€ì ˆ ìœ„ì¹˜ë¥¼ ì¶”ì •í•˜ì§€ë§Œ, ì „ì‹  ìì„¸ë¥¼ ì¶”ì •í•˜ê¸° ìœ„í•´ ì‹œê°ì  ì •ë³´ë§Œ ì‚¬ìš©í•  ë•Œ **3D ë¼ˆ ë°©í–¥ ì¶”ì •**ì€ ì—¬ì „íˆ ë¯¸í•´ê²° ë¬¸ì œ

## Visual Egocentric Pose Estimation

- ëª¸ì— ì°©ìš©í•œ ì¹´ë©”ë¼ì— ì°íŒ ìê¸° ì¤‘ì‹¬ì  ë°ì´í„°ë¡œ ê³ í’ˆì§ˆ ì¬êµ¬ì„± ë¯¸í•´ê²° â†’ ê³„ì¸¡ë˜ì§€ ì•Šì€ ì„ì˜ì˜ í™˜ê²½ì—ì„œ ì‘ë™í•˜ëŠ” ì¬êµ¬ì„± ë°©ë²• í•„ìš”
- ì™¸ë¶€ ì¹´ë©”ë¼ ê¸°ë°˜ ì¸ê°„ í¬ì¦ˆ ì¶”ì • ë°©ë²•ì€ ì‹ ì²´ì˜ ìê¸° ì¤‘ì‹¬ì  ê´€ì ì— ì§ì ‘ ì ìš©í•  ìˆ˜ ì—†ìŒ
- ì‹ ì²´ ì›€ì§ì„ì€ ëª¸ì— ì°©ìš©í•œ ì¹´ë©”ë¼ì—ì„œ ì¶”ë¡ 
    - structure-from-motion([Motion Capture from Body-Mounted Cameras](https://dl.acm.org/doi/pdf/10.1145/1964921.1964926?casa_token=9r_qDXQGq0EAAAAA:0cVi5heZ_Ievlefx1G27Cbx-a1Xcn-HbKLWovwzaFbao563ymnMqx2q3OQJe877qyetLXyqb-2KkLeo))
    - learning-based approaches([Seeing invisible poses: Estimating 3d body pose from egocentric video](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8099856&casa_token=TiQmjLBnSroAAAAA:iXrybsN-c9BmXUg_HNBosCWmzV7qORqLzyeYFWM_c-IkVV6iL9W_2uQpk9hVsuD_ssjSURfbWg8&tag=1), [Cyclops: Wearable and Single-Piece Full-Body Gesture Input Devices](https://dl.acm.org/doi/pdf/10.1145/2702123.2702464?casa_token=MD52GTB0v5kAAAAA:CEiLiizn4qG59Z-9o1OwbFMZVik0PmhgHYhf7M1c8c1hbinRluLU7IIcZqPwdZ2EWpe3tY2dmgnfqU8))
- ì‹ ì²´ë¥¼ ì§ì ‘ ê´€ì°°í•˜ì§€ ì•Šìœ¼ë©´ í¬ì¦ˆ ì¶”ì • ì •í™•ë„ ì œí•œ â†’ ì°©ìš©ìì˜ ì‹ ì²´ ëŒ€ë¶€ë¶„ì„ ë³¼ ìˆ˜ ìˆëŠ” **ë¨¸ë¦¬ ì°©ìš© í•˜í–¥ wide-FoV ì¹´ë©”ë¼**ë¡œ ê°œì„ 
- ìµœê·¼ ë‹¨ì¼ ë¨¸ë¦¬ ì°©ìš© ì¹´ë©”ë¼ ë·° ê¸°ë°˜ ë°©ë²•ì€ ìì„¸ ì¶”ì • ê°œì„ ì„ ìœ„í•´ less-obtrusively ì¥ì°©ëœ ì¹´ë©”ë¼ë¥¼ ì‚¬ìš© â†’ But, ê´‘ë²”ìœ„í•˜ê²Œ ìˆ˜ìš©í•˜ê¸°ì—ëŠ” ë„ˆë¬´ ëˆˆì— ë”
- ëª¸ì— ì°©ìš©í•œ ì¹´ë©”ë¼ë¡œ ì•„ë˜ìª½ ëª¸ì— ê°€ê¹Œìš´ ì‹œì•¼ë¥¼ ì‚¬ìš©í•˜ëŠ” ì ‘ê·¼ë²•ì€ self-occlusion ë° ì‹œì•¼ ë°– jointì˜ ë¬¸ì œ ë¯¸í•´ê²°

## Inertial Pose Estimation

- ì¸ì²´ ìì„¸ ì¶”ì •ì€ ì‹ ì²´ ì°©ìš© ê´€ì„± ì¸¡ì • ì¥ì¹˜(**IMU**)ë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜í–‰
- IMUëŠ” ë¹ ë¥¸ ì›€ì§ì„ì„ í¬ì°© ë° ì¹´ë©”ë¼ ë·°ì— ê°€ë ¤ì§€ëŠ” ì‹ ì²´ ë¶€ìœ„ë¥¼ ì¶”ì  â†’ But, ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ì¸¡ì • ë…¸ì´ì¦ˆì™€ driftë¡œ ì¸í•´ ì–´ë ¤ì›€ì„ ê²ªì–´ ì´ˆê¸° ìì„¸ì— ëŒ€í•œ ì„¸ì‹¬í•œ **ë³´ì •**ì´ í•„ìš”
- **ì„¼ì„œ ì°©ìš© ìˆ˜ìš©ì„±**ì„ ë†’ì´ê¸° ìœ„í•´, ì—°ì†ì ì¸ ë°©í–¥ê³¼ ê°€ì†ì„ ì‚¬ìš©í•˜ì—¬ IMUì˜ ìˆ˜ë¥¼ ì¤„ì„
- IMUëŠ” ì†ëª©ê³¼ ë°œëª©ì—ë§Œ ì°©ìš©í•˜ë©°, ì‚¬ë¼ì§„ ìœ„ìª½ íŒ”ê³¼ í—ˆë²…ì§€ ë°©í–¥ì€ ì•„ë˜ìª½ ë¼ˆì™€ ìœ„ìª½ ë¼ˆì˜ ë™ì‘ì´ ë†’ì€ ìƒê´€ ê´€ê³„ê°€ ìˆë‹¤ê³  ê°€ì •í•¨ìœ¼ë¡œì¨ ì¶”ì •
- ìœ ì‚¬í•œ ì¸¡ì •ìœ¼ë¡œ ì—¬ëŸ¬ í¬ì¦ˆê°€ ê°€ëŠ¥í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— í¬ì¦ˆ ëª¨í˜¸ì„± â†’ ë¯¸ë˜ í”„ë ˆì„ ë˜ëŠ” ì „ì²´ ì‹œí€€ìŠ¤ì™€ ê°™ì€ ë” ë§ì€ ì‹œê°„ì  ì¸¡ì •ì„ ì‚¬ìš©í•˜ì—¬ ë¶€ë¶„ì ìœ¼ë¡œ í•´ê²°
- ì´ ë¬¸ì œë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì‹œê° ë° ê´€ì„± ì„¼ì„œ ìœµí•©ì€ IMUì™€ ê³µë™ìœ¼ë¡œ ì™¸ë¶€ ì§€í–¥ ì¹´ë©”ë¼ë¥¼ í™œìš©í•˜ì—¬ 3D ì‹ ì²´ ìì„¸ë¥¼ ê³„ì‚°
- ì™¸ë¶€ ì§€í–¥ ì¹´ë©”ë¼ì˜ ì‹œê°ì  ìì„¸ ì¶”ì •ì¹˜ëŠ” ê´€ì„± ì„¼ì„œì˜ ê°€ëŠ¥í•œ 3D í¬ì¦ˆë¥¼ ì œí•œí•˜ê³  IMU ì¸¡ì • ë…¸ì´ì¦ˆë¥¼ ì™„í™”í•˜ëŠ” ë° ë„ì›€ â†’ ì§€ê¸ˆê¹Œì§€ ì™„ì „í•œ ì‹ ì²´ ê°€ì‹œì„±ì„ ìš”êµ¬, ì´ëŠ” ìê¸° ì¤‘ì‹¬ì  ê´€ì ì—ì„œëŠ” ê±°ì˜ ë‹¬ì„±í•  ìˆ˜ ì—†ìŒ

# WEARABLE CAPTURE AND EGOCENTRIC DATASET

## Eyeglasses and IMUs Prototype

**ëª©í‘œ** : ì•ˆê²½, ì†ëª© ë°´ë“œ ë° ì‹ ë°œê³¼ ê°™ì´ ì¼ë°˜ì ìœ¼ë¡œ ì°©ìš©í•˜ëŠ” í’ˆëª©ì— ì„¼ì„œê°€ ë‚´ì¥ëœ ì™„ì „ ëª¨ë°”ì¼ í…”ë ˆí”„ë ˆì¦ŒìŠ¤ ì‹œìŠ¤í…œì„ ê°œë°œí•˜ëŠ” ê²ƒ  
**í”„ë¡œí† íƒ€ì…** : ì•ˆê²½í…Œ ì¹´ë©”ë¼ & 4ê°œ IMU(ì†ëª©ê³¼ ë°œëª©ì˜ Xsens MTw Awinda)ê³¼ ë°‰ ëŸ¬ë‹ ê¸°ë°˜ ê¸°ìˆ 
![Untitled](/assets/images/image_Pose/Untitled 1.png)

## Egocentric Visual+Inertial Human Pose Dataset

- í”„ë¡œí† íƒ€ì… í—¤ë“œì…‹ê³¼ 8ê°œì˜ IMUë¥¼ ì°©ìš©í•œ ì‚¬ìš©ìë¡œ ìƒˆë¡œìš´ ì¸ê°„ í¬ì¦ˆ ë°ì´í„° ì„¸íŠ¸ë¥¼ ìˆ˜ì§‘
- ì‹¤ì œ ì „ì‹  3D ê´€ì ˆì€ ìº¡ì²˜ ìŠ¤íŠœë””ì˜¤ì—ì„œ ì—¬ëŸ¬ ê°œì˜ ë²½ ì¥ì°©í˜• ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ì—¬ íšë“
![Untitled](/assets/images/image_Pose/Untitled 2.png)
- training : 22 sequences, evaluation : 9 sequences
- 6 human subjects, for a total of **38k** frames of visual+inertial data
    - **visual data**
        - **real image** : 11kê°œ ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ ê· ì¼í•˜ê²Œ ìƒ˜í”Œë§í•˜ê³  ì „ì²´ ê¸°ë¡ì—ì„œ ìˆ˜ë™ìœ¼ë¡œ í•„í„°ë§
        - **synthetic image** : 38kê°œì˜ í•©ì„± ì´ë¯¸ì§€ëŠ” ì˜ë¥˜ ë° ë°°ê²½ ì§ˆê°, í—¤ë“œê¸°ì–´ ë³€í™˜ ë“± **random augmentation**ì„ í†µí•´ ì‹¤ì œ ë°ì´í„°ì—ì„œ ì‹ ì²´ í¬ì¦ˆë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±
        - ê° joint visibility(label : visible, occluded, outside the FoV)ëŠ” ìê¸° ì¤‘ì‹¬ ì´ë¯¸ì§€ì— íˆ¬ì˜ëœ ì‹ ì²´ ëª¨ë¸ì˜ z-bufferë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ì •
        - ëª¸í†µ ê´€ì ˆ(ëª©, ì–´ê¹¨, ì—‰ë©ì´)ì€ ë¼ˆ ìì„¸ ì¶”ì •ì„ ìœ„í•œ ë¿Œë¦¬ ê´€ì ˆë¡œì„œ í•„ìˆ˜ì ì¸ ì—­í• ì„ í•˜ê¸° ë•Œë¬¸ì— occlusionì— ê´€ê³„ì—†ì´ ëˆˆì— ë³´ì´ëŠ” ê²ƒìœ¼ë¡œ í‘œì‹œ
    - **inertial data**
        - 8ê°œ ì„¼ì„œì˜ ê´€ì„± ë°ì´í„°ë¡œ ì‹œê° ë°ì´í„°ì™€ ë™ê¸°í™” ë° ë³´ì •
        - 38k í”„ë ˆì„ì˜ ì‹¤ì œ IMU ë°ì´í„°ë¥¼ ì •ë©´ì—ì„œ í›„ë©´ìœ¼ë¡œ í¬ì¦ˆë¥¼ ë¯¸ëŸ¬ë§, ì¸¡ë©´ì—ì„œ ì—°ì†ì ìœ¼ë¡œ ë¶€ë“œëŸ½ê²Œ í¬ì¦ˆ ë°©í–¥ì„ ì¡°ì •, ë¬´ì‘ìœ„ ê°€ì†ë„ ë…¸ì´ì¦ˆ ë„ì…ì„ í†µí•´ ì¦ê°•

# EGOCENTRIC RECONSTRUCTION METHOD

- **ì‹œê°-ê´€ì„± ì„¼ì„œ**ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” **ì •ë³´ê°€ í¬ì†Œ**í•˜ì—¬ ì „ì‹  ìì„¸ë¥¼ ìì²´ì ìœ¼ë¡œ ì¶”ì •í•  ìˆ˜ ì—†ìŒ
    1. íŒ”ë‹¤ë¦¬ ì›€ì§ì„ì€ ì‹ ì²´ì— ì˜í•´ ìì£¼ ê°€ë ¤ì§€ê±°ë‚˜ ì¹´ë©”ë¼ ì‹œì•¼ë°–ì— ìˆê¸° ë•Œë¬¸ì— ë³´ì´ì§€ ì•ŠìŒ
    2. IMUëŠ” íŒ”ëšê³¼ ë‹¤ë¦¬ ì•„ë˜ìª½ì—ë§Œ ì°©ìš©í•˜ë¯€ë¡œ íŒ” ìœ„ìª½ê³¼ í—ˆë²…ì§€ ë°©í–¥ì´ ì—†ìŒ

â†’ **visibility-aware visual pose network and a temporally integrated visual and inertial pose network** ì œì•ˆ

![Untitled](/assets/images/image_Pose/Untitled 3.png)


**Stage1**  
visibility-aware 3D joint detector networkëŠ” ë‘ ê°œì˜ ìê¸° ì¤‘ì‹¬ì  í•˜í–¥ ì‹œì•¼ì—ì„œ ê´€ì°°í•  ìˆ˜ ìˆëŠ” jointì˜ 3D ìœ„ì¹˜ë¥¼ ì¶”ì •í•˜ë©°, ê°ì§€ëœ 3D jointëŠ” **VSLAM**ì„ í†µí•´ ì¶”ì •ëœ í—¤ë“œì…‹ í¬ì¦ˆë¥¼ ì‚¬ìš©í•˜ì—¬ world spaceìœ¼ë¡œ ë³€í™˜  
**Stage2**   
í•˜ë¶€ ë¼ˆ(íŒ”ëš, ì•„ë˜ìª½ ë‹¤ë¦¬)ì™€ ìƒë¶€ ë¼ˆ(ìœ„ìª½ íŒ”, í—ˆë²…ì§€)ì˜ 3D ë°©í–¥ì€ ê°ê° visual-inertial IMU offset calibratorì™€ temporal visual-inertial orientation networkë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ì •  
**Stage3**  
parametric body modelì˜ ëª¨ì–‘ê³¼ í¬ì¦ˆëŠ” Stage2ì—ì„œ ì¶”ì •ëœ ì „ì‹  3D joint ìœ„ì¹˜ì™€ ë°©í–¥ì„ ì‚¬ìš©í•˜ì—¬ ì„¤ì •

ğŸ’¡ **VSLAM(Visual Simultaneous localization and mapping)** | ì‹œê° ê¸°ë°˜ì˜ ë™ì‹œì  ìœ„ì¹˜ì¶”ì • ë° ì§€ë„ì‘ì„±ìœ¼ë¡œ ì£¼ë³€ í™˜ê²½ì— ëŒ€í•˜ì—¬ ì§€ë„ë¥¼ ì‘ì„±í•˜ë©´ì„œ ë™ì‹œì— ì´ í™˜ê²½ì„ ê¸°ì¤€ìœ¼ë¡œ ì¹´ë©”ë¼ì˜ ìœ„ì¹˜ì™€ ë°©í–¥ì„ ê³„ì‚°í•˜ëŠ” ê³¼ì •


## 3D Body Representation

### **SMPL**(skinned multi-person linear model) parametric body model

: ì²´í˜•ê³¼ í¬ì¦ˆë¥¼ ë‚˜íƒ€ë‚´ê¸° ìœ„í•œ ëª¨ë¸
- 3D ê°œì²´ëŠ” vertexì™€ triangleë¡œ í‘œì‹œë˜ê³  ê°œì²´ê°€ ë” ì„¸ë¶€ì ì¼ìˆ˜ë¡ ë” ë§ì€ vertex í•„ìš” â†’ **ì¸ê°„**ì˜ 3D ë©”ì‹œ í‘œí˜„ì€ ì¶•ì´ í‚¤, ëš±ëš±í•¨, ê°€ìŠ´ ë‘˜ë ˆ, ë°° í¬ê¸°, í¬ì¦ˆ ë“±ê³¼ ê°™ì€ **ì €ì°¨ì›** ê³µê°„ìœ¼ë¡œ ì••ì¶•ë  ìˆ˜ ìˆìŒ
- ë‘ ê°€ì§€ ìœ í˜•ì˜ ë§¤ê°œ ë³€ìˆ˜ë¡œ ì¸ê°„ í”¼í—˜ìë¥¼ ì¸ì½”ë”©
    - **Shape parameter** $\beta$ : a shape vector of 10 scalar value, ë” í¬ê±°ë‚˜ ë” ì‘ì€ ë°©í–¥ì„ ë”°ë¼ ì¸ê°„ í”¼í—˜ìê°€ íŒ½ì°½/ì¶•ì†Œë˜ëŠ” ì–‘ìœ¼ë¡œ í•´ì„
    - **Pose parameters** $\theta$ : a pose vector of 24x3 scalar value, ë§¤ê°œ ë³€ìˆ˜ì— ëŒ€í•œ ê´€ì ˆì˜ ìƒëŒ€ íšŒì „ì„ ìœ ì§€í•˜ê³  ê° íšŒì „ì€ ì¶•-ê° íšŒì „ í‘œí˜„ì—ì„œ ì„ì˜ì˜ 3D ë²¡í„°ë¡œ ì¸ì½”ë”©

![Untitled](/assets/images/image_Pose/Untitled 4.png)

- linear blend skinningì„ í†µí•´ 6480ê°œì˜ verticeë¥¼ ê°€ì§„ **triangular mesh** $\mathcal{M}(\theta,\beta)$ì„ ë³€í˜•

ğŸ’¡ linear blend skinning | ì–´ë–¤ 3ì°¨ì› ë¬¼ì²´ë¥¼ ì»´í“¨í„° ê·¸ë˜í”½ìœ¼ë¡œ í˜•ìƒí™”ì‹œí‚¬ ë•Œì— ì‚¬ëŒì˜ ë¼ˆ êµ¬ì¡°(skeleton structure)ë¡œë¶€í„° Meshë¥¼ ë§Œë“œëŠ” ì‘ì—…
    
    

### Bone representation

![Untitled](/assets/images/image_Pose/Untitled 5.png)

- ë¼ˆ $i$ëŠ” ë‘ ê°œì˜ ì—°ê²°ëœ **jointì™€ transform**ì— ì˜í•´ ì •ì˜
    - local bone rotation ì§‘í•© í‘œí˜„ $\theta$ ëŒ€ì‹ , **global transform ì§‘í•©** $T^{M}\in \mathbb{R}^{4\times 4}$ìœ¼ë¡œ ì •ì˜ëœ ë™ë“±í•œ ë¼ˆ í‘œí˜„ ì‚¬ìš©
    - **Body Mesh space**ëŠ” $M$ìœ¼ë¡œ, **Skeleton space**ëŠ” $S$ë¡œ í‘œí˜„
    
- global spaceì˜ skeletal bone transformation $T_{i}^{S}\in \mathbb{R}^{4\times 4}$ ì„ pose in the skeleteonìœ¼ë¡œ í‘œí˜„
    
    $$
    \begin{equation*} T_{i}^{S}=\begin{bmatrix} R_{i}^{S} & J_{p(i)}\\ 0 & 1 \end{bmatrix} \tag{1} \end{equation*}
    $$
    
    - $R^{S}=[s_{x},s_{y},s_{z}]\in \mathbb{R}^{3\times 3}$ : bone rotation
    - $J_{p}$ : base joint position
    
- $R^{S}$ì˜ ì—´ ë²¡í„°ëŠ” ë¼ˆì˜ **3D ì¶•**ì„ í˜•ì„±
    - $s_{y}=R^{[:,2]}$ : base(parent)ì—ì„œ tip(child) ê¹Œì§€ ë¼ˆ ë°©í–¥ $d_{i}$
        
        $$
        d_{i}=(J_{i}-J_{p(t)})/(\Vert J_{i}-J_{p(i)}\Vert)
        $$
        
    - íšŒì „ìœ¼ë¡œë¶€í„° ê³„ì‚°ëœ ë¼ˆì˜ ë°©í–¥
    
    $$
    \begin{equation*} d_{i}=d(R_{i})=R_{i}^{[:,2]} \tag{2} \end{equation*}
    $$
    
- **pose parameter** $T_{i}^{M}$ëŠ” $T_{i}^{S}$ìœ¼ë¡œ ì§ì ‘ ê³„ì‚°
    
    $$
    \begin{equation*} T_{i}^{M}=T_{i}^{S}(T_{i,0}^{S})^{-1} \tag{3} \end{equation*}
    $$
    
    - $T_{i}^{T}$ ì€ rest pose ì‹œ identity matrix
    - $T_{i,0}^{S}$ : bind pose matrixë¡œ **ì¢Œí‘œ í”„ë ˆì„ ë§¤í•‘** $\mathcal{F}^{M}\mapsto \mathcal{F}^{S}$
    - $T_{i,0}^{S}$ ëŠ” joint positions in the rest pose of the body modelë¥¼ ì‚¬ìš©í•˜ì—¬ ê³„ì‚°ë˜ë©°, $\beta$ê°€ ë³€ê²½ë  ë•Œë§Œ ì—…ë°ì´íŠ¸
    - $J_{0}$ : $(T^{M})^{-1}(J)$ rest poseì˜ joint ìœ„ì¹˜ 
    - $J_{0}$ëŠ” shaped verticeì—ì„œ **joint regressor** $\mathcal{J}$ì— ì˜í•´ ì„¤ëª…
    

### Estimate the body shapeÂ $\beta$

- $E_{shape}$ì„ **ìµœì†Œí™”**í•˜ì—¬ unposedëœ joint $J_{0}$ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹ ì²´ í˜•íƒœ $\beta$ë¥¼ ì¶”ì •
    
    $$
    \begin{equation*} E_{shape}=\sum_{i=1}^{K}\left\Vert\left(T_{i}^{M}\right)^{-1}\left(J_{i}\right)-\mathcal{J}_{i}\left(\mathcal{M}_{0}+\mathcal{B}_{s}(\beta)\right)\right\Vert_{2}^{2}+w_{s}\Vert\beta\Vert_{2}^{2} \tag{4} \end{equation*}
    $$
    
    - $w_{s}=0.001$ : weight for the regularization term
    - $K = 13$ : number of joint
    - $\mathcal{M}_{0}$ : mean shape â†’ reshape vertices
    - $\mathcal{B}_{s}(\beta)$ : linear blend shapes â†’ reshape vertices
    - $\Vert\beta\Vert_{2}^{2}$ : PCA ê°’ì„ ìµœì†Œí™”í•¨ìœ¼ë¡œì¨ ê° ì£¼ì„±ë¶„ ê°„ì˜ ê°„ê·¹ì„ ì¤„ì„

---

## V**isibility-Aware 3D Joint Detection Network**

- ì¹´ë©”ë¼ë¡œ ì–»ì€ joint visibility ì •ë³´ë¥¼ í†µí•´ ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” jointë¥¼ **ê±°ë¶€**í•˜ê³  ê´€ì°° ê°€ëŠ¥í•œ ê´€ì ˆë§Œ ì¶”ì •
    - **intput** : $m\times m$ egocentric images ($m=320$)
- ë¨¸ë¦¬ì— ì°©ìš©í•˜ëŠ” ì™€ì´ë“œ FoV ì¹´ë©”ë¼ ì´ë¯¸ì§€ì—ì„œ í•˜ì²´ ê´€ì ˆì€ ìƒì²´ ê´€ì ˆë³´ë‹¤ ìƒë‹¹íˆ ì‘ê²Œ ë‚˜íƒ€ë‚¨

### Network Structure for the 3D Joint Detector

![Untitled](/assets/images/image_Pose/Untitled 7.png)

- 2D ì¸ê°„ í¬ì¦ˆ ì¶”ì •ì— ì‚¬ìš©ë˜ëŠ” ***Stacked Hourglass* ì•„í‚¤í…ì²˜**ë¥¼ 3D joint ì¶”ì • ë„¤íŠ¸ì›Œí¬ë¡œ **í™•ì¥**

ğŸ’¡ stacked hourglass networks for human pose estimation | featureëŠ” ì‹ ì²´ì™€ ê´€ë ¨ëœ ë‹¤ì–‘í•œ ê³µê°„ ê´€ê³„ë¥¼ ê°€ì¥ ì˜ í¬ì°©í•˜ê¸° ìœ„í•´ ëª¨ë“  ì²™ë„ì— ê±¸ì³ ì²˜ë¦¬ë˜ê³  í†µí•©ëœë‹¤. í•´ë‹¹ ë…¼ë¬¸ì€ intermediate supervisionê³¼ í•¨ê»˜ ì‚¬ìš©ë˜ëŠ” ë°˜ë³µì ì¸ ìƒí–¥ì‹ í•˜í–¥ì‹ ì²˜ë¦¬ê°€ ë„¤íŠ¸ì›Œí¬ ì„±ëŠ¥ í–¥ìƒì— ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ ë³´ì—¬ì¤€ë‹¤. 
    

- **DSNT íšŒê·€ ëª¨ë“ˆ**ì„ ì‚¬ìš©í•˜ì—¬ íˆíŠ¸ë§µì—ì„œ 2D ì¢Œí‘œë¥¼ ì¶”ì • â†’ íš¨ìœ¨ì„± ì¦ê°€

ğŸ’¡ DSNT : differentiable spatial to numerical transform | ì…ë ¥ ì´ë¯¸ì§€ì˜ **ê´€ì‹¬ ì§€ì ì— ëŒ€í•œ ìˆ˜ì¹˜ ì¢Œí‘œë¥¼ ì¶”ë¡ **í•˜ëŠ” ë”¥ ëŸ¬ë‹ ì ‘ê·¼ë²• ì—°êµ¬ë¡œ, ê¸°ì¡´ convolutional neural network-based ì†”ë£¨ì…˜ì€ heatmap matching ì ‘ê·¼ ë°©ì‹ or fully connected output layer ì¢Œí‘œ ì¡°ì • íšŒê·€ì´ë‹¤. DSNT ê³„ì¸µì€ í›ˆë ¨ ê°€ëŠ¥í•œ ë§¤ê°œ ë³€ìˆ˜ë¥¼ ì¶”ê°€í•˜ì§€ ì•Šê³  ì™„ì „íˆ ë¯¸ë¶„í•  ìˆ˜ ìˆìœ¼ë©° ì¢‹ì€ ê³µê°„ ì¼ë°˜í™”ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. íˆíŠ¸ë§µ ë§¤ì¹­ê³¼ ë‹¬ë¦¬ DSNTëŠ” ë‚®ì€ íˆíŠ¸ë§µ í•´ìƒë„ì—ì„œ ì˜ ì‘ë™í•˜ë¯€ë¡œ ê¸°ì¡´ì˜ ê´‘ë²”ìœ„í•œ fully convolutional architectureì˜ ì¶œë ¥ ë ˆì´ì–´ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ DSNTëŠ” ê¸°ì¡´ ê¸°ìˆ ì— ë¹„í•´ ì¶”ë¡  ì†ë„ì™€ ì˜ˆì¸¡ ì •í™•ë„ ì‚¬ì´ì˜ ë” ë‚˜ì€ ê· í˜•ì„ ì œê³µí•œë‹¤.
    
    

**1. Hourglass ëª¨ë“ˆì€ ì²« ë²ˆì§¸ $K$ ì±„ë„ì˜ heatmap $H$ì™€ ë§ˆì§€ë§‰ $K$ ì±„ë„ì˜ inverse depthmap $D$ ì¶”ë¡ **

- **Heatmap** $H\in \mathbb{R}^{(m/4)\times(m/4)\times K}$
    - Softmax ë ˆì´ì–´ì— ì˜í•´ confidence map $V$ë¡œ ì •ê·œí™”
- **Inverse Depthmap** $D\in \mathbb{R}^{(m/4)\times(m/4)\times K}$
    - jointì— ëŒ€í•œ ì •ê·œí™”ëœ inverse depth ê°’ì„ í¬í•¨í•˜ëŠ” heatmap
    - ì •ê·œí™”ëœ inverse depth ê°’ : $(d_{max}-d)/d_{max}$
        - $d_{max}=2$(meter)ëŠ” ìµœëŒ€ ê¹Šì´
        - ì¹´ë©”ë¼ì— ê°€ê¹Œìš´ ê±°ë¦¬ì—ëŠ” ë” ë†’ì€ ê°’, ë” ë¨¼ ê±°ë¦¬ì—ëŠ” near-zero ê°’ í• ë‹¹

**2. íšŒê·€ ëª¨ë“ˆì€ $H$ì—ì„œ ì •ê·œí™”ëœ confidence map $V$ë¡œë¶€í„° $2D$ ì¢Œí‘œ $\mathbf{p}$ë¥¼ ì¶œë ¥**

- $V$ëŠ” X ë° Y ì¢Œí‘œ í–‰ë ¬ì˜ ë‚´ì ì— ì˜í•´ $2D$ ì¢Œí‘œ $\mathbf{p}$ë¡œ ë³€í™˜
- ì‹ ë¢° $\tilde{v}$ì™€ ê¹Šì´ $d$ëŠ” ê°ê° $V$ì™€ $D$ë¡œ ì¶”ì •ëœ $\mathbf{p}=(x,y)$ ì¢Œí‘œì—ì„œ ì½í˜
- ì‹ ë¢° $\tilde{v}$ê°€ ì¶©ë¶„íˆ í´ ë•Œ ì¢Œí‘œ $\mathbf{p}$ê°€ ìœ íš¨í•˜ê³  ê°€ì‹œì„± $v$ëŠ” 1ë¡œ ì„¤ì •, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ 0ìœ¼ë¡œ ì„¤ì •

**3. ì¶œë ¥ìœ¼ë¡œì„œ ì—°ê²°ëœ $H$ì™€ $D$ëŠ” ë‹¤ìŒ ìŠ¤í…Œì´ì§€ì˜ ì…ë ¥ìœ¼ë¡œ ì „íŒŒ = Intermediate Supervision**

- raw inverse depth íŒë…ì¹˜ëŠ” ë‹¤ì‹œ ê¹Šì´ $d$(meter)ë¡œ ë³€í™˜
![Untitled](/assets/images/image_Pose/Untitled (7).png)

**4. ë‹¨ì¼ ì…ë ¥ ì´ë¯¸ì§€ê°€ ì£¼ì–´ì§€ë©´, 4ë‹¨ê³„ ë„¤íŠ¸ì›Œí¬ëŠ” $3D$ joint ì¢Œí‘œê°€ ê³„ì‚°ë˜ëŠ” $\mathbf{p}$,$D,V$ë¥¼ ì¶œë ¥**

- $3D$ **joint ìœ„ì¹˜**ëŠ” ì¹´ë©”ë¼ calibration matrixë¥¼ ì‚¬ìš©í•œ **back-projecting$(x,y,d)$**ìœ¼ë¡œ ê³„ì‚°

### Network **Loss function**

$$
\begin{equation*}\mathscr{L}_{joint_{-}net}= \mathscr{L}_{DSNT}+\mathscr{L}_{V}+\mathscr{L}_{D}\end{equation*}
$$

- ground truth binary visibility $v^{gt}$ : visible jointëŠ” 1, invisible jointëŠ” 0
- $\mathscr{L}_{DSNT}$ : **regression loss** â†’ $v^{gt}=1$
    
    $$
    \begin{equation*} \mathscr{L}_{DSNT}=\sum_{i=1}^{K}v_{i}^{gt}\cdot[\Vert \mathbf{p}_{i}^{gt}-\mathbf{p}_{i}\Vert _{2}^{2}+\mathcal{D}(V_{i}\Vert\mathcal{N}(\mathbf{p}_{i}^{gt},\sigma I_{2}))] \tag{5} \end{equation*}
    $$
    
    - $\mathcal{N}(\mu,\sigma)$ : 2D Gaussian map drawn atÂ Î¼ Â with standard deviationÂ Ïƒ(Ïƒ=1 Â for training)
    - $\mathcal{D}(\cdot\Vert \cdot)$ : $H$ê°€ 2D Gaussian mapê³¼ ìœ ì‚¬í•˜ê²Œ í•˜ê¸° ìœ„í•œ Jensen-Shannon ë°œì‚°

ğŸ’¡ Jensenâ€“Shannon divergence | ë‘Â í™•ë¥  ë¶„í¬Â ì‚¬ì´ì˜ ìœ ì‚¬ì„±ì„ ì¸¡ì •í•˜ëŠ” ë°©ë²•

- $\mathscr{L}_{V}$ : **invisibility loss** â†’ $v^{gt}=0$
    
    $$
    \begin{equation*} \mathscr{L}_{V}=\sum_{i=1}(1-v_{i}^{gt})\cdot\Vert H_{i}\Vert _{2}^{2} \tag{6} \end{equation*}
    $$
    
    - ë³´ì´ì§€ ì•ŠëŠ” jointì— ëŒ€í•´ $H$ë¥¼ ì œë¡œ íˆíŠ¸ë§µìœ¼ë¡œ ì–µì œ
    - $V$ì—ì„œ ê· ì¼í•œ ë¶„í¬ë¥¼ ê°•í™”, ë³´ì´ì§€ ì•ŠëŠ” ê´€ì ˆì— ëŒ€í•´ ì‹ ë¢° ê°’ì´ ë” ì‘ì•„ì§€ë„ë¡ ì¥ë ¤
    
- .$\mathscr{L}_{D}$ : **depth loss** â†’ $v^{gt}=1$
    
    $$
    \begin{equation*} \mathscr{L}_{D}=\sum_{i=1}^{K}v_{i}^{gt}\cdot\Vert \mathcal{M}(\mathbf{p}_{i}^{gt},\sigma I_{2})\ominus(D_{i}-D_{i}^{gt})\Vert _{2}^{2} \tag{7} \end{equation*}
    $$
    
    - $\mathcal{M}(\mu,\sigma)$ : 2D binary maskmap drawn atÂ Î¼ with radiusÂ Ïƒ
    - $\ominus$ : ì•„ë‹¤ë§ˆë¥´ ê³± (Hadamard product)ìœ¼ë¡œ ê°™ì€ í¬ê¸°ì˜ ë‘ í–‰ë ¬ì˜ ê° ì„±ë¶„ì„ ê³±í•˜ëŠ” ì—°ì‚°
    - ê¹Šì´ ë§µì€ **ê´€ì‹¬ joint ì˜ì—­**ë§Œ í›ˆë ¨ â†’ ë§ˆìŠ¤í¬ ë§µì„ ì‚¬ìš©í•˜ì§€ ì•Šì„ ë•Œ ê¹Šì´ ë§µ ì¶œë ¥ì´ 0ì´ ë˜ëŠ” **ê³¼ì í•©ì„ ë°©ì§€**í•˜ê¸° ìœ„í•´ ì™¸ë¶€ ì˜ì—­ì´ ë³€ê²½ë˜ì§€ ì•Šë„ë¡ í•¨

### The network is trained in multiple stages

- $2D$ ë ˆì´ì–´ëŠ” **[MPII Human Pose Dataset](http://human-pose.mpi-inf.mpg.de/)**ì—ì„œ low-level texture featuresë¥¼ í•™ìŠµí•˜ë„ë¡ í›ˆë ¨ â†’ **íšŒê·€ ì†ì‹¤** $\mathscr{L}_{DSNT}$ë§Œ í›ˆë ¨ì— ì‚¬ìš©ë˜ê³  visibilityëŠ” ë¬´ì‹œ
- ë„¤íŠ¸ì›Œí¬ëŠ” ì „ì²´ ì†ì‹¤ í•¨ìˆ˜ $\mathscr{L}_{joint _{-}net}$ë¡œ **intermediate supervision**ì´ ì ìš©ë˜ì–´ í›ˆë ¨
- ì˜¤ë¥¸ìª½ ì¹´ë©”ë¼ ì´ë¯¸ì§€ë¥¼ ë’¤ì§‘ì–´ ì¶œë ¥ joint ì¢Œí‘œë¥¼ ë’¤ë¡œ ë’¤ì§‘ì–´, ì™¼ìª½ ì¹´ë©”ë¼ ì´ë¯¸ì§€ì™€ ë™ì¼í•œ ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ë‘ ê°œì˜ í•˜í–¥ ì¹´ë©”ë¼ ë·° ì‚¬ì´ì˜ ëŒ€ì¹­ í™œìš© â†’ ë‘ ë·° ëª¨ë‘ì— ëŒ€í•œ êµìœ¡ ë° ëŸ°íƒ€ì„ì—ì„œ **ë‹¨ì¼ ë„¤íŠ¸ì›Œí¬**ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•¨

## Temporally, Multi-view Consistent Joint Estimation

- 3D jointëŠ” ì¢Œìš° í•˜í–¥ ì¹´ë©”ë¼ ë·°ì—ì„œ **ë…ë¦½ì **ìœ¼ë¡œ ê°ì§€, camera clibration matricesë¥¼ ì‚¬ìš©í•˜ì—¬ **ë‹¨ì¼ 3D ê³µê°„ìœ¼ë¡œ ì¬íˆ¬ì˜**
- **ì˜ëª»ëœ ê°ì§€**ë¡œ ì¸í•´ ìƒëŒ€ jointì™€ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” jointì˜ ê²°ê³¼ê°€ **multi-view-consistentì™€** **ì‹œê°„ì ìœ¼ë¡œ ì¼ê´€ë˜ë„ë¡** í•„í„°ë§ë¨
    1. jointì˜ raw detectionì€ ë¼ˆ ë°©í–¥ $d_{i}$ê°€ ì‹œê°„ì ìœ¼ë¡œ ì¼ê´€ì„±ì´ ì—†ëŠ” ê²½ìš° ê±¸ëŸ¬ì§€ë©°, ì´ëŠ” í”„ë ˆì„ ê°„ì— 30**Â°** ì´ìƒì˜ ë³€í™”ë¡œ ì •ì˜
    2. **í•„í„°ë§ëœ ì¸¡ì •**ì€ ê°€ì¤‘ì¹˜ í•©ê³„ë¥¼ **ìµœì†Œí™”**í•˜ì—¬ multi-view-consistent ë° ì‹œê°„ì ìœ¼ë¡œ ì¼ê´€ëœ joint ìœ„ì¹˜ $X$ë¥¼ ì¶”ì •í•˜ëŠ”ë° ì‚¬ìš©
    
    $$ E_{proj}+w_{d}E_{dep}+w_{l}E_{len}+w_{t}E_{temp} $$
    
    - ê°€ì¤‘ì¹˜ ì„¤ì •
        - $w_{d}=1,w_{l}=0,w_{t}=10$ : ëª©, ì—‰ë©ì´ ë° ì–´ê¹¨ë¥¼ í¬í•¨í•œ ëª¸í†µ joint
        - $w_{d}= 2, w_{l}=2,w_{t}=1$ : íŒ” joint
        - $w_{d}=1,w_{l}=5,w_{t}=2$ : ë‹¤ë¦¬ joint
    - **Projection cost** : $E_{proj} = \Sigma_{c=1}^{C}\Vert \mathbf{p}_{c} - P _{c}\cdot X\Vert _{2}$
        - $C$ : number of views
        - $\mathbf{p}_{c}$ : 2D location measurement in camera image c
        - $P_{c}$ : camera câ€™s projection matrix
    - **Depth cost** : $E_{dep} = \Sigma_{c=1}^{C}\Vert d_{c}-T_{c}^{[3,:]}\cdot X\Vert _{2}$
        - $d_{c}$ : depth measurement in camera *c*
        - $T_{c}^{[3,:]}$ : third row of the extrinsic matrix of camera *c*
    - **Bone length consistency** : $E_{len} = \Vert X_{l}-\Vert X_{p}-X\Vert _{2}\Vert _{2}$
        - ê³¨ê²© ê¸¸ì´ëŠ” ì´ˆê¸°í™”ë¶€í„° ìƒˆë¡œìš´ ê²€ì¶œ ì¸¡ì •ì„ í†µí•´ í‰ê· í™”ê¹Œì§€ ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ìœ ì§€
        - ì´ˆê¸° ê³¨ê²© ê¸¸ì´ëŠ” ì •ì§€ ìì„¸ ì‹œ ì‹ ì²´ ëª¨ë¸ì—ì„œ ê°€ì ¸ì™€ ëª¨ë¸ê³¼ ê²€ì¶œëœ ì²™ì¶” ê¸¸ì´ ì‚¬ì´ì˜ ë¹„ìœ¨ë¡œ ìŠ¤ì¼€ì¼ë§
        - $X_{p}$ : parent jointâ€™s position
        - $X_{l}$ : bone length of joint $X$
    - **Temporal smoothness cost** : $E_{temp} = \Vert X_{t-1}-X\Vert _{2}$
        - $X_{t-1}$ : joint position in the previous frame
- í—¤ë“œì…‹ ê³µê°„ 3D joint ìœ„ì¹˜ $X$**â†’ VSLAM**ì„ í†µí•´ íšë“í•œ **í˜„ì¬ ì¶”ì •ëœ headset pose** â†’ 3D ì„¸ê³„ ê³µê°„ joint ìœ„ì¹˜  $J$ë¡œ ë³€í™˜
- ì „ì²´ í”„ë¡œì„¸ìŠ¤ëŠ” ì§ì ‘ì ì¸ triangulationì„ ì‚¬ìš©í•  ë•Œë³´ë‹¤ **ì •í™•ë„ í–¥ìƒ**

![Untitled](/assets/images/image_Pose/Untitled 9.png)

![Untitled](/assets/images/image_Pose/Untitled 10.png)



## Visual-Inertial Alignment

- ì‚¬ëŒì˜ ìì„¸ëŠ” í•´ë‹¹ ë¼ˆì˜ ë°©í–¥ì„ ì¶”ì í•˜ëŠ” **ì‹ ì²´ ì°©ìš© ê´€ì„± ì„¼ì„œ(IMU)**ë¡œ ì¶”ì •
- IMUëŠ” ì¼ë°˜ì ìœ¼ë¡œ íŠ¹ì • ì´ˆê¸° í¬ì¦ˆë¥¼ ì‚¬ìš©í•˜ì—¬ ë³´ì • â†’ ì•½ê°„ ì˜ëª» ì •ë ¬ëœ ì‹ ì²´ ì°©ìš© IMUë„ ì‹œê°ì  ê´€ì„± ì¼ê´€ëœ í¬ì¦ˆ ì¶”ì •ì„ ë°©í•´í•˜ì—¬ ë¶€ì •í™•í•œ ê²°ê³¼ë¥¼ ì´ˆë˜

### Coordinate frame transformations

![Untitled](/assets/images/image_Pose/Untitled 11.png)
(a) ì‚¬ì „ ì •ì˜ëœ wear poseë¥¼ ë‚˜íƒ€ë‚´ëŠ” ìŠ¤ì¼ˆë ˆí†¤ ê³µê°„ $R^{SI}$ì— ëŒ€í•œ ê´€ì„± ì„¼ì„œ íšŒì „  
(b) ì˜ëª» ì •ë ¬ëœ IMUë¥¼ ë³´ì •í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” IMU íšŒì „ ì˜¤í”„ì…‹ $R^{W}$

- ì‹œê°„ì— ë”°ë¼ ì•„ë˜ìª½ ë¼ˆ ë°©í–¥ì˜ Visual-InertialìŒì„ ì‚¬ìš©í•˜ì—¬ IMU íšŒì „ ì˜¤í”„ì…‹ $R^{W}$ë¥¼ ì¶”ì •í•¨ìœ¼ë¡œì¨ **ë¶€ì •í™•ì„±** í™•ì¸

### Computing the lower bone

- ì‹œê°„ ë‹¨ê³„ $t$ì— ë”°ë¥¸ ë¼ˆ íšŒì „ $R_{t}^{S}$ì€ í•˜ë¶€ ë¼ˆì— ì¥ì°©ëœ IMUë¥¼ í†µí•´ ê³„ì‚°
    
    $$
    \begin{equation*} R_{t}^{S}=R^{W}\cdot R_{t}^{I}\cdot(R^{SI})^{-1}\cdot R_{0}^{S} \tag{8} \end{equation*}
    $$
    
    - ê°€ì‹œì„± ê´€ê³„ X
    - $R_{t}^{I}$ : orientation read from the Inertial sensor at timeÂ $t$
    - $R_{0}^{S}$ : rotation from $T_{0}^{S}$
    - $(R^{SI})^{-1}$ : $\mathcal{F}^{S}\rightarrow \mathcal{F}^{I}$ë¡œ í”„ë ˆì„ ë§¤í•‘
- Inertial lower bone direction
    
    $$
    \begin{equation*}
    d_{t}^{I}=R_{t}^{I}\cdot(R^{SI})^{-1}\cdot d(R_{0}^{S})
    \tag{9}
    \end{equation*}
    $$
    
    - $d_{i}=d(R_{i})=R_{i}^{[:,2]}$
    - $d(R_{0}^{S})$  : bone direction in the rest pose

### Estimate IMU rotation offset

- IMU íšŒì „ ì˜¤í”„ì…‹ $R^{W}$ì€ ë™ì¼í•œ ë¼ˆì˜ ì‹œê°ì  ê²€ì¶œê¸°ì—ì„œ ì¸¡ì •ì„ ì‚¬ìš©í•  ìˆ˜ ìˆì„ ë•Œë§ˆë‹¤ ì—…ë°ì´íŠ¸
    - prior bone direction $d(R_{1}^{S}), \ldots,d(R_{t}^{S})$ **=** visual bone direction **$d_{1}^{V}, \ldots,d_{t}^{V}$**
- ì„¼ì„œê°€ ì •í™•íˆ ì§€ì •ëœ ìœ„ì¹˜ì™€ ë°©í–¥ìœ¼ë¡œ ì°©ìš©ëœ ê²½ìš° $R^{W}=I_{3}$
- $R^{W}$ì€ **ìµœì†Œ ììŠ¹ë²•**ë¥¼ í•´ê²°í•˜ì—¬ ì¼ë ¨ì˜ Visual $d^{V}$ ë° Inertial $d^{I}$ ë°©í–¥ìœ¼ë¡œë¶€í„° ì¶”ì •:
    
    $$
    \begin{equation*}
    \min_{R^{W}}\sum_{t}\Vert d_{t}^{V}-R^{W}\cdot d_{t}^{I}\Vert _{2}^{2}
    \tag{10}
    \end{equation*}
    $$
    
    - ëª¨ë“  $(d^{I},\ d^{V})$ ìŒì— ëŒ€í•´ ìœ„ ì‹ì„ ê³„ì‚°í•˜ëŠ” ê²ƒì€ ê³„ì‚° ì§‘ì•½ì 
    - ì˜¨ë¼ì¸ k-d íŠ¸ë¦¬ êµ¬ì¡°ë¥¼ ê°€ì§„ Algorithm 1ì— ì„¤ëª…ëœ ì˜¨ë¼ì¸ k-í‰ê·  ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ visual-inertial ìŒì„ ê·¸ë£¹í™”í•˜ê³  $R^{W}$ë¥¼ ì—…ë°ì´íŠ¸
        
        ![Untitled](/assets/images/image_Pose/Untitled 12.png)
        
        - At runtime, k-d íŠ¸ë¦¬ì—ì„œ ê³ ì •ëœ k=200ê°œì˜ í´ëŸ¬ìŠ¤í„° ìŒ ìœ ì§€
        - ìƒ˜í”Œë§ ì „ëµì€ êµ°ì§‘ ê°„ ê±°ë¦¬ë¥¼ ìµœëŒ€í™” â†’ êµ°ì§‘ì˜ ê· ì¼í•œ ë¶„í¬ë¥¼ ì„ í˜¸, ì„ í˜• í‘œë³¸ì˜ ìˆ˜ë¥¼ ìµœì†Œí™”

## Temporal Visual-Inertial Orientation Network

- ìƒë¶€ ë¼ˆ **ë°©í–¥**ì€ í•˜ë¶€ ë¼ˆ **ì›€ì§ì„**ê³¼ ë†’ì€ ìƒê´€ ê´€ê³„ â†’ ìƒë¶€ ë¼ˆ ì›€ì§ì„ì€ ì—¬ëŸ¬ ë°©í–¥ ê°€ëŠ¥ â†’  ìƒë¶€ ë¼ˆì˜ **ì‹œê°ì  ê´€ì°°**ì„ ì‚¬ìš©
    - ì„¼ì„œë¡œ ê³„ì¸¡ëœ í•˜ë¶€ ë¼ˆ(***i***)ì™€ ê³„ì¸¡ë˜ì§€ ì•Šì€ ìƒë¶€ ë¼ˆ(***u***) êµ¬ë³„
    - ë³´ì •ëœ ì•„ë˜ ë¼ˆ ë°©í–¥ $R_{\mathbf{i}}^{S}$ì€ IMU offset matrix $R_{\mathbf{i}}^{W}$ìœ¼ë¡œ ê³„ì‚°


### Estimate upper bone

- $a_{\mathbf{i}}^{S}=R_{\mathbf{i}}^{H}\cdot a_{\mathbf{i}}^{I}$
    - $a_{\mathbf{i}}^{I}$ : raw acceleration
    - $R^{H}$ : $R^{W}$ì—ì„œ ê³„ì‚°ëœ ìœ„ìª½ ë°©í–¥ì„ ë”°ë¼ íšŒì „í•˜ëŠ” Heading resetì„ ë‚˜íƒ€ë‚´ëŠ” IMU acceleration offset matrix

- ì´ì „ $R_{\mathbf{i}}^{S}$, í•˜ë¶€ ë¼ˆì— ëŒ€í•œ $a_{\mathbf{i}}^{S}$, ì‹œê°ì ì¸ ìƒë¶€ ë¼ˆ ë°©í–¥ $d_{\mathbf{u}}^{V}$ì˜ ê°€ìš©ì„± â†’ ë¹„ê³„ì¸¡ ìƒë¶€ ë¼ˆ $R_{\mathbf{u}}^{S}$ë¥¼ ì¶”ì •
    - $d(R_{u}^{S})=d_{u}^{V}$
    - ì‹ ì²´ ë°©í–¥ì— ë¶ˆë³€í•˜ê¸° ìœ„í•´, $R_{\mathbf{i}}^{S}$, $a_{\mathbf{i}}^{S}$, $d_{\mathbf{u}}^{V}$ëŠ” ì‹œê°„ $t$ì—ì„œ root joint(ì—‰ë©ì´ ì¤‘ì‹¬) ë°©í–¥ $R_{root}^{S}$ì— ëŒ€í•´ ì •ê·œí™”:
    
    $$
    \begin{equation*} R^{N}(t)=(R_{root}^{S}(t))^{-1}\cdot R_{\mathbf{i}}^{S}(t) \tag{11} \end{equation*}
    $$
    
    - $a_{\mathbf{i}}^{S}\rightarrow a^{N}$ê³¼  $d_{\mathbf{u}}^{V}\rightarrow d^{N}$ ë¹„ìŠ·í•˜ê²Œ ì •ê·œí™”
        
    - N : Normalized torso space
        

### Temporal visual-inertial orientation network architecture

![Temporal visual-inertial orientation network architecture. ì¼ë ¨ì˜ visual-inertial input feature vectors xë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ê³„ì¸¡ ë°©í–¥ yë¥¼ ì¶”ì •í•œë‹¤. ëª¨ë“  ë ˆì´ì–´ëŠ” í›ˆë ¨ì—ì„œ dropout 0.2ë¥¼ ì‚¬ìš©í•œë‹¤. ê´„í˜¸ ì•ˆì˜ ìˆ«ìëŠ” ê° ë ˆì´ì–´ì˜ ì¶œë ¥ ì¹˜ìˆ˜ì´ë‹¤.](/assets/images/image_Pose/Untitled 13.png)

- ì¼ë ¨ì˜ input features $\mathbf{x}=[x_{t-n+1},\ \ldots,x_{t}]$ì—ì„œ ê³„ì¸¡ë˜ì§€ ì•Šì€ ê³¨ê²© ë°©í–¥ì„ ì˜ˆì¸¡í•˜ëŠ” í•¨ìˆ˜ $\mathbf{x}\rightarrow y_{t}$ì„ í•™ìŠµí•˜ëŠ” ì‘ì—…
    - LSTMì„ ëŠ¥ê°€í•˜ëŠ” **Transformer network**ë¥¼ ì‚¬ìš©
    - ì…ë ¥ ì‹œí€€ìŠ¤ëŠ” ë§ˆì§€ë§‰  $n=20$ í”„ë ˆì„ì˜ ì¸¡ì •ìœ¼ë¡œ êµ¬ì„±
- **input feature vector**
    
    $$
    \begin{equation*}
    x_{t}=[r_{t}, \omega_{t},a_{t},v_{t}\cdot d_{t}]^{T}
    \tag{12}
    \end{equation*}
    $$
    
    - input feature vectorëŠ” íšŒì „, ì†ë„ ë° ê°€ì†ë„ë¡œ ëŒ€í‘œë˜ëŠ” í•˜ë¶€ ë¼ˆ ì›€ì§ì„ì„ í†µí•©
    - $r_{t}$ : ë²¡í„°í™”ëœ $R_{i}^{N}$ìœ¼ë¡œ, 4ê°œì˜ ì…ë ¥ ë¼ˆì— ëŒ€í•´ $[r_{1}^{N}(t),\ \ldots,r_{4}^{N}(t)]^{T}$ë¥¼ ë‚˜íƒ€ëƒ„ â†’ $\omega_{t}$, $a_{t}$ì™€ $v_{t}\cdot d_{t}$ë„ ë¹„ìŠ·í•˜ê²Œ ì •ì˜
    - $\omega_{i}^{N}(t)$ : $R_{i}^{N}(t)$ì™€ $R_{i}^{N}(t-1)$ ì‚¬ì´ì˜ ê°ì†ë„
    - ìƒë¶€ ë¼ˆ $i$ì˜ jointê°€ ì‹œê°ì  ê²€ì¶œê¸°ë¡œ ì œê³µë  ë•Œ, $d_{i}^{N}$ ë°©í–¥ì´ ì¶”ê°€ë˜ê³  visibility $v_{i}$ê°€ 1ë¡œ ì„¤ì •
        - ì œê³µë˜ì§€ ì•Šì„ ë•Œ, $v_i=0.1^{-3}$ ê³¼ $d_{i}^{N}=(1,1,1)$ ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ëª¨ë‘ 0ìœ¼ë¡œ ì„¤ì •í•˜ëŠ” ê²ƒë³´ë‹¤ ì„±ëŠ¥ì´ ë” ìš°ìˆ˜
    - $x_{t}$ì˜ ì°¨ì›ì€ 4ê°œì˜ IMU ê³„ì¸¡ ë¼ˆ$(r_{t},\omega_{t},a_{t})$ì™€ 4ê°œì˜ ë¹„ ê³„ì¸¡ ë¼ˆ$(v_{t}\cdot d_{t})$ë¡œ $(9+3+3+3)\cdot 4=72$
- **output vector**
    - ë²¡í„°í™”ëœ ë¹„ê³„ì¸¡ ê³¨ê²© ë°©í–¥ $y_{t}=[r_{1}^{o}(t),\ \ldots,r_{4}^{o}(t)]^{T}$ í¬í•¨
    - $r_{i}^{o}$ê°€ ì¶œë ¥ ë°©í–¥ $R_{i}^{o}(t)$ë¡œ reshape
    - $y_{t}$ì˜ ì°¨ì›ì€ 4ê°œì˜ ìœ„ìª½ ë¼ˆì— ëŒ€í•´ (9) $\cdot 4=36$
- **loss function**

$$
\begin{equation*} \mathscr{L}_{bone_{-}net}=\Vert y-y^{gt}\Vert _{2}^{2}+\sum_{j=1}^{4}v_{i}^{gt}\cdot acos(d(R_{i}^{o}),d_{i}^{gt}) \tag{13} \end{equation*}
$$

- orientation lossì€ ground truth $y^{gt}$ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸¡ì •
    - $d(R^{o})$ëŠ” ê³„ì‚°ëœ ì¶œë ¥ ê³¨ê²© ë°©í–¥ì„ ë‚˜íƒ€ëƒ„
    - ground truth $d^{gt}$ ê³¨ê²© ë°©í–¥ì— ì˜í•´ íŒ¨ë„í‹°ê°€ ë°œìƒí•˜ë©°, ì´ëŠ” ì¶œë ¥ ê³¨ê²© ë°©í–¥ì´ ì‹œê°ì  ì…ë ¥ ê³¨ê²© ë°©í–¥ê³¼ ì¼ì¹˜í•˜ë„ë¡ ì¥ë ¤
    - ì´ í•­ì€ $v^{gt}=1$ì¸ ê²½ìš°ì—ë§Œ ê³„ì‚°
- At run-time, ì •ê·œí™”ëœ ëª¸í†µ ê³µê°„ì˜ ì¶”ì • $R^{o}$ëŠ” ì‹ (11)ì„ ì‚¬ìš©í•˜ì—¬ ì„¸ê³„ ê³µê°„ì˜ $R_{\mathrm{u}}^{S}$ë¡œ ë³€í™˜


---

## Deformable Body Model Fitting

- í•´ë‹¹ ì—°êµ¬ì˜ íŒŒì´í”„ë¼ì¸ì€ full body shapeì™€ pose ì¶”ì • : joint positions Jì™€ bone rotation $R^{S}$
    - ê´€ì°°ë˜ì§€ ì•Šì€ ê´€ì ˆ ìœ„ì¹˜ëŠ” $R^{S}$ì˜ **forward kinematics**ì™€ í•´ë‹¹ ë¼ˆ ê¸¸ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³µêµ¬
    - ì „ì‹  joint ìœ„ì¹˜ $J$ë¥¼ ì´ìš©í•˜ì—¬ ì‹$(4)$ ë¥¼ í’€ì–´ ì²´í˜• ì—…ë°ì´íŠ¸

$$
\begin{equation*} E_{shape}=\sum_{i=1}^{K}\left\Vert\left(T_{i}^{M}\right)^{-1}\left(J_{i}\right)-\mathcal{J}_{i}\left(\mathcal{M}_{0}+\mathcal{B}_{s}(\beta)\right)\right\Vert_{2}^{2}+w_{s}\Vert\beta\Vert_{2}^{2} \tag{4} \end{equation*}
$$

- bone rotation $R^{S}$ëŠ” ê²€ì¶œëœ visual direction output $d^{V}$ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ê°€ë¡œ ë³´ì •(ì‚¬ìš© ê°€ëŠ¥ ì‹œ)
    - ì¶”ì •ëœ $R^{S}$ëŠ” ì‹œê°„ì  ì¼ê´€ì„±ì´ ìˆì§€ë§Œ ëª¨ì…˜ ë˜ëŠ” ê°€ì‹œì„±ì— ê°‘ì‘ìŠ¤ëŸ¬ìš´ ë³€í™”ê°€ ë°œìƒí•  ê²½ìš° ëª¨ì…˜ì´ over-smoothed â†’ ë¼ˆ ë°©í–¥ $R^{S}$ë¥¼ $d^{V}$ì— ë” ê°€ê¹ê²Œ ë§ì¶° í•´ê²° â†’ ë³€í™”ì— ëŒ€í•œ ë” ë¹ ë¥¸ ë°˜ì‘ ì´‰ì§„
- $d^{V}$ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê²½ìš°, ë³´ì •ëœ ë¼ˆ íšŒì „ $\overline{R}^{S}$ë¥¼ ì¶”ì •:
    
    $$
    \begin{equation*} \bar{R}^{S}=R^{v2v}(d(R^{S}),\ \alpha\cdot d^{V}+(1-\alpha)\cdot d(R^{S}))\cdot R^{S} \tag{14} \end{equation*}
    $$
    
    - $R^{v2v}(v_{1},v_{2})$ : $V_{1}$ë¡œë¶€í„° $v_{2}$ ë²¡í„°ë¡œì˜ íšŒì „
    - $a=0.8$
- joint ìœ„ì¹˜ $\bar{J}$ëŠ” $\overline{R}^{S}$ë¥¼ ì‚¬ìš©í•˜ëŠ” forward kinematicsì— ì˜í•´ ì—…ë°ì´íŠ¸
    - ì¶”ì •ëœ joint $\bar{J}$ëŠ” ì‹œê°„ì ìœ¼ë¡œ ì¼ê´€ëœ joint ì¶”ì •ì„ ìœ„í•´ ë‹¤ìŒ í”„ë ˆì„ìœ¼ë¡œ **ì „ì†¡**
- í¬ì¦ˆ íŒŒë¼ë¯¸í„° $T^{M}$ì€ ì‹$(1)$ê³¼ ì‹$(3)$ì˜  $\overline{R}^{S}$ì™€ $\bar{J}$ë¥¼ ì´ìš©í•˜ì—¬ ì¶”ì •

$$
\begin{equation*} T_{i}^{S}=\begin{bmatrix} R_{i}^{S} & J_{p(i)}\\ 0 & 1 \end{bmatrix} \tag{1} \end{equation*}
$$

$$
[ \begin{equation*} T_{i}^{M}=T_{i}^{S}(T_{i,0}^{S})^{-1} \tag{3} \end{equation*} 
$$

# Results and Evaluation

- ë³¸ ì—°êµ¬ì˜ 3D í¬ì¦ˆ ì¶”ì • ë°©ë²•ì€ ì´ì „ ë°©ë²•ê³¼ ì§ì ‘ ë¹„êµí•  ìˆ˜ ì—†ìŒ
    - ì™¸ë¶€ ì¹´ë©”ë¼ ê¸°ë°˜ ë°©ë²•ì€ ëª¨ë“  jointë¥¼ ë³¼ ìˆ˜ ìˆì–´ì•¼ í•¨
    - ì´ì „ì˜ visual+interial ìœµí•© ì ‘ê·¼ë²•ì€ 10ê°œ ì´ìƒì˜ IMUë¥¼ í•„ìš”ë¡œ í•¨
    - ë³¸ ì—°êµ¬ëŠ” ëª¸ ì „ì²´ë¥¼ í¬ì°©í•˜ì§€ ëª»í•˜ëŠ” ì…ë ¥ ìŠ¤í…Œë ˆì˜¤ í—¤ë“œì›¨ì–´ ë·° ë° ì†ëª©ê³¼ ë°œëª©ì— ì¥ì°©ëœ ê´€ì„± ì„¼ì„œ 4ê°œë§Œ ì‚¬ìš©
- **HG3D(stereo stacked hourglass 3D)**ëŠ” ì‹ $(6)$ ì˜ visibility awareness termì—†ì´ $4.2$ì ˆì˜ 3D joint detectorë¥¼ ì‚¬ìš©í•˜ëŠ” ì‹œê°ì  ì „ìš© ë°©ë²•
    - ëˆˆì— ë³´ì´ëŠ” ê´€ì ˆê³¼ ë³´ì´ì§€ ì•ŠëŠ” ê´€ì ˆì„ ëª¨ë‘ ê°ì§€í•˜ê³ , 4.3ì ˆì— í‘œì‹œëœ ê²ƒì²˜ëŸ¼ ë‘ ê°œì˜ ì•„ë˜ìª½ ì¹´ë©”ë¼ ë·°ì—ì„œ ê´€ì ˆì„ ë³‘í•©í•˜ì—¬ ì „ì‹  3D ê´€ì ˆ ìœ„ì¹˜ë¥¼ ìƒì„±
    - 3D ê³¨ê²© íšŒì „ì€ inverse kinematics ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ê²€ì¶œëœ ê´€ì ˆë¡œë¶€í„° ì¶”ì •
    - ë³¸ ì—°êµ¬ëŠ” ê³µê°œì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ìê¸°ì¤‘ì‹¬ì  ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•´ monocular stacked hourglass 3Dë¥¼ ë³„ë„ë¡œ í‰ê°€í–ˆìœ¼ë©° ê²½ìŸë ¥ ìˆëŠ” ê²°ê³¼
    ![Untitled](/assets/images/image_Pose/Untitled (5).png)
- **DIP**ëŠ” ì†ëª©, ë°œëª©, ëª¸í†µ ë° ë¨¸ë¦¬ì— ë°°ì¹˜ëœ 6ê°œì˜ ì„¼ì„œë¥¼ ì‚¬ìš©í•˜ëŠ” IMU ê¸°ë°˜ ë°©ë²•ì¸ Deep Inertial Poser[14]
    - ë³¸ ì—°êµ¬ëŠ” ë¨¸ë¦¬ ë° ëª¸í†µì˜ ë°©í–¥ê³¼ ê°€ì†ë„ì— ëŒ€í•œ ì‹¤ì¸¡ê°’ì„ ì‚¬ìš©í–ˆê³  ë¹„êµì—ì„œëŠ” ì‚¬ì§€ ì›€ì§ì„ë§Œ í¬í•¨
    - ì§€ìƒ ì‹¤ì¸¡ ëª¨ì–‘ê³¼ ì‚¬ì „ ë³´ì •ëœ ê´€ì„± ì¸¡ì •ì„ ì‚¬ìš©
    - LSTM ì•„í‚¤í…ì²˜ì˜ ìµœìƒì˜ êµ¬ì„±ê³¼ í•¨ê»˜ 20ê°œì˜ ê³¼ê±° í”„ë ˆì„ê³¼ 5ê°œì˜ ë¯¸ë˜ í”„ë ˆì„ì„ í¬í•¨
    - ëŒ€ì¡°ì ìœ¼ë¡œ, ë³¸ ì—°êµ¬ì˜ ìì²´ì  ë°©ë²•ì€ ëŸ°íƒ€ì„ì— ì‹ ì²´ í˜•íƒœì™€ ì„¼ì„œ ë³´ì •ì„ ì¶”ì •í•˜ë©°, ë¯¸ë˜ í”„ë ˆì„ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
- **Ours8**ì€ ì†ëª©, ë°œëª©, íŒ”ëš, í—ˆë²…ì§€ì— ì°©ìš©í•˜ëŠ” 8ê°œì˜ IMUë¥¼ ì‚¬ìš©í•œ ë²„ì „
    - ìƒë¶€ ë¼ˆëŠ” ì‹¤ì œ ì¸¡ì •ì´ ê°€ëŠ¥í•˜ê¸°ì—   $4.5$ì ˆì€ ê±´ë„ˆëœ€
    - ëŒ€ì‹ , $4.4$ì ˆì˜ visual-inertial alignmentì„ ì‹œê°„ ê²½ê³¼ì— ë”°ë¼ 8ê°œì˜ IMU ëª¨ë‘ì— ì ìš©

## Quantitative evaluation
- ì¬êµ¬ì„± ê²°ê³¼ì˜ ì •í™•ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ì¶”ì •ì¹˜ì™€ ì‹¤ì¸¡ì¹˜ ì‚¬ì´ì˜ 3D joint ìœ„ì¹˜ ë° ë°©í–¥ ì˜¤ë¥˜ë¥¼ ë¹„êµí•˜ì—¬ ì‹œìŠ¤í…œ í‰ê°€
    - Ego-VIP ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•œ ê²°ê³¼
    ![Untitled](/assets/images/image_Pose/Untitled (6).png)
    - ëª¨ë“  ë²”ì£¼ì—ì„œ ë³¸ ì—°êµ¬ì˜ ë°©ë²•ì´ HG3D ë° DIPë¥¼ ëŠ¥ê°€
- HG3Dì˜ ì •í™•ë„ëŠ” ë³´ì´ëŠ” jointì— ëŒ€í•´ì„œëŠ” ë…¼ë¬¸ì˜ ë°©ë²•ê³¼ ë¹„ìŠ·í•˜ì§€ë§Œ, ì´ì™¸ëŠ” ìœ„ì¹˜ ì˜¤ë¥˜ê°€ ìƒë‹¹íˆ ë†’ìŒ
    - **IK**ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³„ì‚°ëœ ë°©í–¥ì€ ê´€ì„± ì„¼ì„œì—ì„œ íšë“í•  ë•Œë³´ë‹¤ í›¨ì”¬ ëœ ì •í™•
    - **ì†Œìˆ˜ì˜ ê´€ì„± ì„¼ì„œ**ë¼ë„ joint ìœ„ì¹˜ì™€ ë°©í–¥ì—ì„œ **ìì„¸ ì •í™•ë„**ë¥¼ í¬ê²Œ í–¥ìƒ
- DIPëŠ” ìœ„ì¹˜ì™€ ë°©í–¥ ëª¨ë‘ì—ì„œ ë…¼ë¬¸ì˜ ë°©ë²•ë³´ë‹¤ í›¨ì”¬ ë‚®ì€ ì •í™•ë„ì™€ ë†’ì€ ë¶„ì‚°
    - **í¬ì†Œí•œ ì‹œê° ì •ë³´**ë„ IMU ê¸°ë°˜ ë°©ë²•ì— **í†µí•©**í•˜ë©´ **ì—°ì†ì  ì •í™•ë„**ê°€ í¬ê²Œ ì•ˆì •í™”ëœë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤Œ
    - ë³´ì´ì§€ ì•ŠëŠ” ê´€ì ˆì˜ ê²½ìš°, ì •í™•ë„ëŠ” ì—¬ì „íˆ DIPë¥¼ ëŠ¥ê°€í•˜ë©´ì„œ ê´€ì„± ì„¼ì„œì— ì „ì ìœ¼ë¡œ ì˜ì¡´í•˜ê¸° ë•Œë¬¸ì— í¬ê²Œ ë–¨ì–´ì§
    - ë…¼ë¬¸ì˜ íŠ¸ëœìŠ¤í¬ë¨¸ ë„¤íŠ¸ì›Œí¬ ê¸°ë°˜ ë°©í–¥ ì¶”ì •ì€ DIPì˜ LSTM ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬ë³´ë‹¤ ë¶„ì‚°ì´ ì ìŒ

## Qualitative evaluation
![Untitled](/assets/images/image_Pose/Untitled 14.png)
- HG3DëŠ” (a)ì—ì„œ ê°€ë ¤ì§„ ì˜¤ë¥¸ìª½ ë¬´ë¦ê³¼ ë°œëª©ì„, (b)ì—ì„œ ì™¸ë¶€ ê´€ì ˆì„ ê°ì§€í•˜ì§€ ëª»í•¨
- DIPëŠ” (a)ì—ì„œ ì™¼ìª½ ë¬´ë¦ ì˜¬ë¦¬ê¸°ë¥¼, (b)ì—ì„œ ì† ë“¤ê¸°ë¥¼ ë¶€ì¡±í•˜ê²Œ ê°ì§€í•˜ê³ , (c)ì—ì„œ ì ì€ IMU ì…ë ¥ì˜ í¬ì¦ˆ ëª¨í˜¸ì„±ìœ¼ë¡œ ì¸í•´ ì˜ëª»ëœ í•˜ì²´ í¬ì¦ˆë¥¼ ì¶œë ¥
- Ours8(dense-IMUs) ë³€í˜•ì€ ëª¨ë“  ë¼ˆê°€ IMUë¡œ ê³„ì¸¡ë˜ê¸° ë•Œë¬¸ì— ì„¸ ê°€ì§€ ë²”ì£¼ ëª¨ë‘ì—ì„œ ìµœê³ ì˜ ì„±ëŠ¥
    - ê·¸ëŸ¬ë‚˜ IMUê°€ 4ê°œì— ë¶ˆê³¼í•œ ë°©ë²•ì˜ ì •í™•ë„ëŠ” Ours8ê³¼ ë¹„ìŠ·í•˜ë©°, HG3D ë˜ëŠ” DIPë³´ë‹¤ í›¨ì”¬ ìš°ìˆ˜í•œ ì„±ëŠ¥

# FUTURE WORK
- ì‚¬ìš©ìì˜ ì‚¬ì§€ë§Œ ì¶”ì í•˜ê¸° ë•Œë¬¸ì— **í™˜ê²½ê³¼ì˜ ìƒí˜¸ ì‘ìš©**ì„ ëª¨ë¸ë§í•˜ì§€ ì•Šìœ¼ë©°, ì‹ ì²´ ëª¨ë¸ì˜ í‘œë©´ì—ì„œ **í† í´ë¡œì§€ ë˜ëŠ” ì§ˆê° ë³€í™”**ë¥¼ ê°ì§€í•  ìˆ˜ ì—†ìŒ  
    â†’ ì˜ì ì´ë™, ë„¥íƒ€ì´ ì°©ìš© ë“± í† í´ë¡œì§€ ë³€í™”, ë‹¤ë¥¸ ì…”ì¸  ì°©ìš© ë“± ì§ˆê° ë³€í™” ë“± ê°ì²´ì™€ì˜ ìƒí˜¸ì‘ìš© ì§€ì›ì„ ì¶”ê°€í•  ê³„íš  
    â†’ 3D í™˜ê²½ ì ‘ì´‰ì„ ì¶”ì •í•¨ìœ¼ë¡œì¨ ë¬¼ë¦¬ì ìœ¼ë¡œ íƒ€ë‹¹í•œ ì ‘ê·¼ ë°©ì‹ì„ í™•ì¥í•  ê³„íšì´ë©°, ë‹¤ë¥¸ ì‹ ì²´ ëª¨ë¸ê³¼ í•¨ê»˜ ë³´ë‹¤ í˜„ì‹¤ì ì¸ ëª¨ì–‘ì„ ë§Œë“¤ ê³„íš
- ê´€ì ˆ ìœ„ì¹˜ ì •í™•ë„ëŠ” ì¶”ì •ëœ ê´€ì ˆì„ ì„¸ê³„ ê³µê°„ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” **VSLAM ê²°ê³¼ì— í¬ê²Œ ì¢Œìš°**ë˜ë©°, VSLAMì´ ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ë¶ˆì•ˆì •í•˜ê±°ë‚˜ ë¶€ì •í™•í•œ ê²½ìš° ì‹ ì²´ ìì„¸ ì •í™•ë„ ê°ì†Œ  
    â†’ ë” ê²¬ê³ í•œ ë¨¸ë¦¬ í¬ì¦ˆ ì¶”ì •ì„ ìœ„í•´ ë‹¤ì¤‘ ì „ë°© ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ê³  IMUë¥¼ í—¤ë“œì…‹ì— í†µí•©í•  ê³„íš
- í˜„ì¬ íŒŒì´í”„ë¼ì¸ì—ì„œ 3D joint ê°ì§€ ë„¤íŠ¸ì›Œí¬ì˜ ê²°ê³¼ëŠ” ì—°ì† ë°©í–¥ ë„¤íŠ¸ì›Œí¬ì— ê³µê¸‰ë˜ë©°, 3D jointê°€ ì˜ëª» ê°ì§€ë˜ë©´ **ì˜¤ë¥˜ê°€ ì „ì²´ì— ì „íŒŒ**  
    â†’ ì˜ëª»ëœ íƒì§€ì— ëŒ€í•œ ê²¬ê³ ì„±ì„ ê°œì„ í•˜ëŠ” ê²ƒë¿ë§Œ ì•„ë‹ˆë¼ ê²°í•©ëœ ë„¤íŠ¸ì›Œí¬ë¥¼ ì¡°ì‚¬í•  ê³„íš
- í˜„ì¬ Physical Therapy (PT) í”„ë¡œí† íƒ€ì…ê³¼ ë‹¬ë¦¬, ë¯¸ë˜ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ í”„ë¡œí† íƒ€ì…ì€ ì–‘ë°©í–¥ í…”ë ˆí”„ë ˆì  ìŠ¤ë¥¼ ë³´ì—¬ì¤„ ê³„íš