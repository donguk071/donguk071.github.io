---
layout: post
title: "[배경지식] MLP part1"
date: 2023-03-27
categories: DL 
photos: /assets/post_images/titleImg/MLP_title.jpg
tags: [DeepLearning, MLP,  ActivationFunction, Perceptron, multilayor, ForwardPropagation]
description: "MLP 개념리뷰(part1) : MLP에 관한 이해가 없다면 향후 여러가지 DL 알고리즘을 이해하기 어렵다. 다른 DL 알고리즘을 다루기 이전 MLP를 먼저 이해하여 보자"
published: true
---

<br/>
<br/>

# MLP(part1)
<br/>
MLP(Multi Layor Perceptron)는 딥러닝의 기본 중 기본이 되는 구조다. 해당 포스팅에서는 이러한 MLP에 구조을 쉽고 자세하게 리뷰 보도록 하겠다.

## 0. Perceptron 이란?
<br/>
**Multi Layor Perceptron에서 Perceptron 은 무엇일까? **

- 딥러닝에서 Perceptron에 의미는 '인공신경망'으로 우리 뇌에 신경 세포와 유사하게 동작하여 이러한 이름을 갖는다. 
- 이러한 Perceptro 은 딥러닝의 핵심 구성요소이며, 단층 perceptron은 단순하며 다양한 개념들을 잘표현하기에 기계 학습의 용어와 원리를 설명하는데 적합하다.

    ![Untitled](/assets/post_images/mlpImg/perceptron.jpg)


아마 MLP및 Perceptron이 처음이신 분들은 위와 같은 구조가 생소하실 수 있다. 이를 이해하기 위해 먼저 Perceptron이 수많은 classification 알고리즘 중 하나라는 점을 인지하고 접근한다면 이해하는데 도움이 될 것이다.




## 1. Structure of Perceptron

<br/>

MLP 모델에 경우 input에는 label 관점에서 다양한 값이 들어갈 수 있다. 들어가는 값이 다양하다 하더라고 모든 input은 일종의 feature의 의미를 갖는다는 공통점이 존재한다. table 데이터에 경우에는 하나의 input node는 column 명이 될 것이고 image 데이터에 경우에는 image의 pixel 값을 flatten한 값들이 될 것이다.

<br/>

> **bias란 무엇일까?**
bias는 activation function의 임치를 정하는데 영향을 줄 수 있다.(activation funtion의 절편으로도 해석가능) 이를 통해 결과적으로 네트워크 혹은 데이터의 분포를 옮기는데 도움을 주는 기능을 한다. 이러한 특징은 더욱 좋은 학습 결과를 얻는데 도움을 줄 수 있다.
> 

<br/>

> **weghit란 무엇일까?**
weghit 란 model이 training 되는 과정에서 업데이트가 이루어 지는 feature에 중요도 값을 의미한다.좀 더 쉽게 말하면 역할은 앞에서 전달 받은 정보를 얼마나 중점적으로 고려할 것인지라고 또한 할 수 있을 것 같다. 이러한 업데이트는 일반적으로 training 과정에서만 이루어진다.

<br/>


## 2. Activation Function

<br/>

Perceptron에서 언급한 activation function이란 무엇이고 왜 사용할까?

복잡한 데이터 분포에 boundary를 주기 위해서는 비선형적인 표현식이 필요하다. 하지만 이때 선형의 함수를 취해준다면 결과 값 또한 선형성을 띄는 결과가 나오게 된다. 따라서 비선형성을 주기 위해 사용되는 함수인 activation function을 사용하여, 결과적으로 일차 결합으로 이루어 지지 않은 비선형 함수를 취해주어야 비선형성을 띄는 boundary 표현식이 나오게 된다. 이러한 방식을 통하여 복잡한 데이터를 잘 나누어주는 경계를 표현할 수 있어진다.

<br/>

>**요약**<br/>
MLP는 데이터 분포를 고차원으로 옮겨가며 단순화 시킨다.
1. 데이터 분포의 차원을 이동 시키며 각 차원에서 최적의 decision boundary 를 그린다.
2. 하나의 decision boundary 는 선형적이라고 볼 수 있지만, 여러 perceptron을 통해 생성된 decision boundary들의 집합은 비선형성을 보인다.
3. 각각의 퍼셉트론 자체는 선형이지만 모두 그 축(axis)이 다르기 때문에 이를 한 좌표공간에서 본다면 당연하게도 비선형의 결정경계가 나온다.
<br/>

[Activation Func 종류](https://junstar92.tistory.com/122)에 관한 추가 자료 


<br/>

## 3. Why multilayor

   ![Untitled](/assets/post_images/mlpImg/mlp.jpg)

<br/>


single layor Perceptron만으로는 `XOR` 문제를 해결하는 것이 불가능하다. activation func을 취해주어 비선형성을 주어 해당 문제를 해결이 가능하다고 생각할 수 있지만,이는 Perceptron이 여러 layor로로 존재할 경우에 해당한다.  결론만 이야기 하자면 Percriotron을 결합하고 layor을 깊게 만들어야 데이터를 더욱 정교한 decisiton boundry로 나누는 것이 가능해지며 이를 이용해 `XOR`같은 문제 또한 해결이 가능하다. 



<br/>

## 4. Forward Propagation
<br/>

거창한 이름에 비해 당연한 개념이다. 앞서 언급한 Perceptron에 기본적인 `flow(input → multiply w → sum → activation func → output)`와 일치한다. 해당 과정을 거치면 최종 예측값을 얻을 수 있다. 




------------------------
_실제 수식을 통한 예제와 kernel mapping에 관해서는 향후 추가하도록 하겠습니다 ^^ _

<br/>

### Kernel mapping
[kermel mapping](https://sanghyu.tistory.com/14) 에 관한 참고 자료


### example

궁금한 점이 있다면 남겨주세요! 함께 고민해보겠습니다.

------------------------
#### Reference
[https://ds-academy.net/chapter-1-introduction-to-dl/](https://ds-academy.net/chapter-1-introduction-to-dl/)